#
# File:   content-mit-8370x-subtitles/U3L4a.txt
#
# Captions for course module
#
# This file has 113 caption lines.
#
# Do not add or delete any lines.  If there is text missing at the end, please add it to the last line.
#
#----------------------------------------

Today we're going to cover the concepts of the error
correction criteria for quantum codes.
And the way I'd like to do that is
to begin with a brief review of what
we have learned for classical coding and quantum
coding so that I can tie all these threads together and use
a single piece of language to describe
the entire set of concepts in the field.
And so I'll rapidly move from classical
to quantum using the same examples that you have seen.
Then I will introduce a new terminology-- a new mechanism--
known as operator measurement.
And using operator measurement, we'll
be able to see a operationalized version of syndrome
measurement; and then the step after syndrome measurement,
which you haven't explicitly seen so far, which is something
called the recovery operation.
And then based on that recovery operation,
we'll be able to formalize what the criteria are for when you
can correct errors and when you cannot correct errors.
And this is a beautiful, phenomenal thing
to know about in quantum error correction.
Questions before I go on?
OK.
So let's begin with a little bit of review.

You may remember that the scenario
for the classical coding began with this notion
of having a noisy channel.
The noisy channel was one in which you would have an input
0 that would stay 0 with a certain probability 1 minus P.
But with a probability of error of P, 0 would turn into a 1,
and this was symmetric, so that 1 could turn into a 0,
or stay unchanged with the same probability of error.
So P is the probability of error.

Now this is called the binary symmetric channel.
And we apply the binary symmetric channel
to a variety of codes.
And then we show that by doing something basic, which
was repetition, we were able to correct for this kind of error,
and other kinds of errors.
And this is also known as a bit-flip error,
when you have a 0 going to a 1 and vise versa.
So what we did not do was to define
what a classical code was.
And I'd like to summarize that for you right now.
Let me define a classical code with some parameters--
n, k, and d.

And this will be a very simple conceptual definition.
This is exceedingly general.
It's not meant to actually be very useful.
And the reason I give you this kind of definition
is because I want you to see the parallel of this definition
with the quantum version of it.
So a classical n, k, d code with three parameters
is defined as a set of 2 to the k n bit
strings in the set of all binary strings,
with a certain property--
with minimum Hamming distance between any code words
in this set of bit strings d.
So I'm not implying any structure
on this set of bit strings.
For it to be a code, you don't have to have that structure.
But remember that what you saw in lecture
was Professor Shor giving you a very special set of such bit
strings, which were generated by a matrix, that
generated a matrix.
And these were called linear classical codes.
And it's very nice to have families of codes like that.
But just for the definition of what a code is in principle,
you don't need to have that kind of a specific definition.
So in order to use this definition, one thing we need
is the Hamming distance.
And I want to make sure you all remember this.
The Hamming distance d between two [INAUDIBLE] x and y,
is the weight of x plus y, where this is the Hamming weight.
That's the number of 1s.
And this here is an bitwise exclusive or between the two
strings x and y.
And for linear codes, when Professor Shor described this,
there was this just an addition sign there.
And what he meant was for it to be modular, too, in the sum.
And when you're using general bit-string codes
like I have here, this is the more general way to look at it.
So let's give an example.

Suppose I encode with three 0s as being
a representation of a logical 0, and three 1s as
being the representation of a logical 1.
What are n, k, and d?

Anyone?

n is equal to--

this is an easy one.
3?
OK.
What's k?
[INAUDIBLE]
I heard somebody say 2, though.
So you can see that the reason it's 1
is because there's only one bit encoded using three bits.
Now what is d?
[INAUDIBLE]
3.
And why is it 3?
It's because you need to flip three bits to go from one word
to the other word.
